{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#''''''denoising network''''''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === Load data ===\n",
    "# Load training signals contaminated with 0dB noise\n",
    "x_train = np.load('C:/AE_noise_localization/x_train_0dB.npy')  \n",
    "# Load corresponding clean training signals\n",
    "y_train = np.load('C:/AE_noise_localization/X_train.npy')       \n",
    "\n",
    "# Load validation signals contaminated with 0dB noise\n",
    "x_val = np.load('C:/AE_noise_localization/x_val_0dB.npy') \n",
    "# Load corresponding clean validation signals\n",
    "y_val = np.load('C:/AE_noise_localization/X_val.npy') \n",
    "\n",
    "\n",
    "x_train = x_train[..., np.newaxis]  # (N, 1024, 1)\n",
    "y_train = y_train[..., np.newaxis]\n",
    "\n",
    "x_val = x_val[..., np.newaxis]  # (N, 1024, 1)\n",
    "y_val = y_val[..., np.newaxis]\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# === Denoising network ===\n",
    "def conv_block(x, filters, kernel_size=3, activation='relu'):\n",
    "    x = layers.Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = layers.Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    x = conv_block(x, filters)\n",
    "    p = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(x, skip, filters):\n",
    "    x = layers.UpSampling1D(size=2)(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "def build_unet_1d(input_length=1024):\n",
    "    inputs = layers.Input(shape=(input_length, 1))\n",
    "    e1, p1 = encoder_block(inputs, 32)\n",
    "    e2, p2 = encoder_block(p1, 64)\n",
    "    e3, p3 = encoder_block(p2, 128)\n",
    "    e4, p4 = encoder_block(p3, 256)\n",
    "    e5, p5 = encoder_block(p4, 512)\n",
    "    e6, p6 = encoder_block(p5, 1024)\n",
    "    b = conv_block(p6, 1024)\n",
    "    d6 = decoder_block(b, e6, 1024)\n",
    "    d5 = decoder_block(d6, e5, 256)\n",
    "    d4 = decoder_block(d5, e4, 128)\n",
    "    d3 = decoder_block(d4, e3, 64)\n",
    "    d2 = decoder_block(d3, e2, 32)\n",
    "    d1 = decoder_block(d2, e1, 32)\n",
    "    outputs = layers.Conv1D(1, kernel_size=1, activation='linear')(d1)\n",
    "    return models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "# Build the model\n",
    "model = build_unet_1d(input_length=1024)\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# === Compile the model ===\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# === Set up EarlyStopping (not used now) ===\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# === Set model saving path ===\n",
    "checkpoint_path = 'C:/localization/denoise_0dB_opt_code.h5'\n",
    "\n",
    "# === Save only the model with the lowest val_loss ===\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,  # Save the whole model (structure + weights)\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === Train for 100 epochs (currently set to 1) ===\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=200,\n",
    "    callbacks=[checkpoint],  # EarlyStopping not used\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Load test signals contaminated with 0dB noise\n",
    "x_test = np.load('C:/AE_noise_localization/x_test_0dB.npy')\n",
    "# Load corresponding clean test signals\n",
    "y_test = np.load('C:/AE_noise_localization/X_test.npy')\n",
    "\n",
    "y_pred = model.predict(x_test, batch_size=2000)\n",
    "\n",
    "\n",
    "y_pred = y_pred.squeeze()\n",
    "\n",
    "def compute_snr(clean, denoised):\n",
    "    signal_power = np.mean(clean ** 2)\n",
    "    noise_power = np.mean((clean - denoised) ** 2)\n",
    "    if noise_power == 0:\n",
    "        return np.inf\n",
    "    snr = 10 * np.log10(signal_power / noise_power)\n",
    "    return snr\n",
    "\n",
    "snr_value = compute_snr(y_test, y_pred)\n",
    "print(f\"Test SNR: {snr_value:.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66162ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#''''''localization network''''''\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.norm(y_true - y_pred, axis=-1))\n",
    "\n",
    "# Load input waveforms for the training set\n",
    "X_train = np.load('C:/AE_noise_localization/X_train.npy')\n",
    "# Load the coordinates (labels) corresponding to the training signals\n",
    "y_train = np.load('C:/AE_noise_localization/y_train_lable.npy')\n",
    "\n",
    "# Load input waveforms for the validation set\n",
    "X_val = np.load('C:/AE_noise_localization/X_val.npy')\n",
    "# Load the coordinates (labels) corresponding to the validation signals\n",
    "y_val = np.load('C:/AE_noise_localization/y_val_lable.npy')\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(1024,))\n",
    "\n",
    "x = layers.Dense(1024, activation='relu')(inputs)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "outputs = layers.Dense(2)(x)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss=euclidean_distance_loss)\n",
    "model.summary()\n",
    "\n",
    "# Checkpoint callback\n",
    "model_path = os.path.join(save_path, 'best_model_OPT.h5')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=2000,\n",
    "    batch_size=3000,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model after training\n",
    "best_model = load_model(\n",
    "    model_path, \n",
    "    custom_objects={'euclidean_distance_loss': euclidean_distance_loss}\n",
    ")\n",
    "# Load input waveforms for the test set\n",
    "X_test = np.load('C:/AE_noise_localization/X_test.npy')\n",
    "# Load the coordinates (labels) corresponding to the test signals\n",
    "y_test = np.load('C:/AE_noise_localization/y_test_lable.npy')\n",
    "\n",
    "best_model = load_model(\n",
    "    model_path, \n",
    "    custom_objects={'euclidean_distance_loss': euclidean_distance_loss}\n",
    ")\n",
    "\n",
    "# Evaluation on test set\n",
    "test_loss = best_model.evaluate(X_test, y_test)\n",
    "print(\"Mean Euclidean distance on the test set:\", test_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
